\chapter{Malsharp Evaluation}
\label{chapter:fifth}

In this chapter we will present our evaluation for \project. We begin by describing the test environment we used for analyzing malware in \labelindexref{section}{fifth:test-env}. Then we describe a typical test scenario and we use a short example to illustrate how the malspec mining algorithm works on a small graph in \labelindexref{section}{fifth:test-scenario}. Finally, we present our evaluation results for a set of malware samples in \labelindexref{section}{fifth:evaluation-results}.

\section{Malware test environment}
\label{fifth:test-env}

\project\ was tested in a sandbox environment: a VMware virtual machine with a distribution of Ubuntu with the Linux 3.7.8 kernel which has been bridged to the local network for Internet access.

To ensure that all the malware samples were tested in the same environment, we used snapshots so that each file was tested on the same virtual machine state. In this way, different malware samples could not influence each other's execution.

\fig[scale=1.0]{src/img/test-env.png}{img:test-env}{Virtual Machine test configuration}

In \labelindexref{Figure}{img:test-env} the snapshot test configuration is shown. The ``Clean malware state'' is the malware test snapshot we mentioned earlier. ``Before cutting off for malware test'' is the VM\abbrev{VM}{Virtual Machine} state before changing the connection type from NAT\abbrev{NAT}{Network Address Translation} to bridge and before removing all ssh keys from the machine.

\section{Test scenario}
\label{fifth:test-scenario}

In a typical test scenario, \project\ receives an XML file which contains the system calls with parameter information that we want to monitor in our executables. We can test for malware specifications only on a subset of the total system calls a Linux operating system has.

For a better comprehension on how the malspec mining algorithm works, we will consider the following example. Let us assume that we want to search for malware specifications with \code{open}, \code{read}, \code{write} and \code{close} system calls. In this example, \code{program_test} will be the malware sample and \code{diff_test} will be the benign program.

The following table presents the system calls that each executable file makes and the relevant argument information for the dependency edges.

\begin{center}
\begin{table}[htb]
  \caption{System calls for program_test and diff_test}
  \begin{center}
  \code{
  \begin{tabular}{cl*{6}l}
     & program_test & diff_test \\
    \hline
    1 & open(...) = fd1 & open(...) = fd1  \\
    2 & close(fd1) & close(fd1)  \\
    3 & open(...) = fd2 & open(...) = fd2 \\
    4 & read(fd2, ...) & read(fd2, ...)  \\
    5 & close(fd2) & close(fd2) \\
    6 & open(...) = fd3 & open(...) = fd3\\
    7 & write(fd3, ...) & close(fd3) \\
    8 & write(fd3, ...) & open(...) = fd4 \\
    9 & write(fd3, ...) & write(fd4, ...) \\
    10 & close(fd3) & read(fd4, ...) \\
    11 & \multicolumn{1}{c}{-} & close(fd4)
  \end{tabular}
  }
  \end{center}
  \label{table:test-programs}
\end{table}
\end{center}

\fig[scale=0.65]{src/img/max-common-edge-set.pdf}{img:max-common-edge-set}{Maximal common edge set. (a) program_test; (b) diff_test.}

In \labelindexref{Figure}{img:max-common-edge-set} the generated graphs for the two programs presented in \labelindexref{Table}{table:test-programs} are shown. For each node we have written its index in the graph and its label.

Although there are three \code{write} calls in \code{program_test} that operate on the same file descriptor, these nodes are not aggregated because of the fourth restriction we added to node aggregation in \labelindexref{Section}{fourth:dep-graphs}. The three nodes cannot be aggregated because of the edges that exist between them.

The maximal common edge set that was determined using McGregor's algorithm is shown by drawing paired nodes with the same colors. The nodes that do not have a matching node in the other graph have no color. The edges connecting them are gray because they are not a part of the maximal common edge set.

After computing the maximal common edge set, its complement in the malware graph is computed. In this particular example, the complement is a single connected graph, so the minimal union step of the algorithm is not required.

Then, a breadth first search is used to find the minimal transversal of the complement. The result of these two steps of the algorithm can be seen in \labelindexref{Figure}{img:min-transversal-compl}. The malspec contains two nodes which are colored red and the black edge connecting them. Because we used a single benign program to find the malspec, this will be the final result of the algorithm.

\fig[scale=0.65]{src/img/min-transversal-compl.pdf}{img:min-transversal-compl}{Minimal transversal of complement graph. (a) program_test; (b) diff_test.}

The complete output from \project\ for \code{program_text} and \code{diff_test} can be seen in \labelindexref{Appendix}{lst:output}.

\section{Evaluation results}
\label{fifth:evaluation-results}

\project\ was tested using the Linux malware samples provided by \cite{open-malware}. All the malware samples that were tested also had additional classification information provided by antivirus software.

As pointed out by Burguers \textit{et al.} in \cite{crowdroid-malware-android}, the increasing number of smartphones on the market with the Android platform, which has a Linux kernel, make malware analysis an important issue.

Therefore, we used two sets of system calls to monitor the malicious and benign programs: a smaller set which was indicated by Burguers \textit{et al.} in their paper about behavior-based detection on Android \cite{crowdroid-malware-android} and a larger set which contained other system calls that might be used for malicious purposes.

The larger set is a superset of the other and has more system calls that use with file descriptors and with socket communication. Only a part of this XML file has been added to this paper as \labelindexref{Appendix}{lst:syscalls-xml} because the original file was two large.

The results for each set of system calls\abbrev{syscall}{system call} can be seen in the following two tables, one per set. The set of benign programs we considered for testing consisted of: \code{ls}, \code{lsmod}, \code{ping} and \code{cat}.

In \labelindexref{Table}{table:mal-analysis-android} and \labelindexref{Table}{table:mal-analysis-all}, we used the following notation:

\begin{itemize}
    \item N - number of nodes of the dependency graph
    \item N' - number of nodes left after node aggregation
    \item E - number of edges of the dependency graph
\end{itemize}

\begin{center}
\begin{table}[htb]
  \caption{Malware sample analysis for android.xml}
  \begin{center}
  \begin{tabular}{lcccccl}
    Sample & N & N' & E & Malspecs & Time & Observed behavior\\
    \hline
    Backdoor.Linux.CGI.a   & 12  & 12  & 5   & 1 & 10.208s & \code{open, read, close} \\
    Backdoor.Linux.Phobi.1 & 36  & 35  & 16  & 1 & 0.0641s & \code{open, read, close} \\
    Trojan.Linux.Rootkit.n & 12  & 11  & 5   & 1 & 0.558s  & \code{open, read, close} \\
    Virus.Linux.Osf.8759   & 692 & 442 & 285 & 0 & 0.725s  & \code{open, read, close} \\
    Virus.Linux.Radix      & 14  & 13  & 4   & 1 & 0.786s  & \code{open, read} \\
    Virus.Linux.Silvio.b   & 46  & 46  & 24  & 1 & 0.983s  & \code{open, read, close} \\
    Virus.Linux.Snoopy.c   & 128 & 93  & 39  & 1 & 1.271s  & \code{open, read, close} \\
    Virus.Linux.Svat.b     & 23  & 23  & 12  & 0 & 0.617s  & \multicolumn{1}{c}{-} \\
  \end{tabular}
  \end{center}
  \label{table:mal-analysis-android}
\end{table}
\end{center}

In \labelindexref{Table}{table:mal-analysis-android}, we show the results for 8 malware samples. Although the initial collection of malware samples had 20 samples, some samples could not be tested because the operating system on our VM did not have all the shared libraries it required in order to run. Also, other samples were actually tools for flooding a range of ip addresses in a network.

Most of the samples generated dependency graphs with a very small number of nodes. This is a consequence of the fact that android.xml contains a very small number of system calls used for monitoring: \code{read}, \code{open}, \code{close}, \code{chmod}, \code{lchown} and \code{access}.

\code{Virus.Linux.Osf.8759} generated the biggest graph and we can see that the node aggregation method reduced the total number of nodes considerably, from 692 to 442.

\begin{center}
\begin{table}[htb]
  \caption{Malware sample analysis for all_syscalls.xml}
  \begin{center}
  \begin{tabular}{lcccccl}
    Sample & N & N' & E & Malspecs & Time & Observed behavior \\
    \hline
    Backdoor.Linux.CGI.a   & 13  & 13  & 5   & 1 & 0.827s  & \code{open, read, close}  \\
    Backdoor.Linux.Phobi.1 & 36  & 35  & 16  & 1 & 0.641s  & \code{open, read, close}  \\
    Trojan.Linux.Rootkit.n & 14  & 14  & 5   & 1 & 1.044s  & \code{open, read, close}  \\
    Virus.Linux.Osf.8759   & 19  & 19  & 9   & 0 & 53m 31s & \code{open, read, fstat}  \\
                           &     &     &     &   &         & \code{read, close; fork}  \\
    Virus.Linux.Radix      & 25  & 22  & 6   & 1 & 0.673s  & \code{open, read, write;} \\ 
                           &     &     &     &   &         & \code{creat, write}       \\
    Virus.Linux.Svat.b     & 25  & 25  & 12  & 0 & 3.495s  & replaces \code{stdio.h}   \\
  \end{tabular}
  \end{center}
  \label{table:mal-analysis-all}
\end{table}
\end{center}

Analysis results for the larger set of system calls is shown in \labelindexref{Table}{table:mal-analysis-all}. The total analysis took longer due to the fact that the generated dependence graphs were larger, especially in the case of the benign programs.

Our implementation succeeded in obtaining malspecs for the analyzed malware samples. The most remarcable result was for the \code{Virus.Linux.Osf.8759} sample, although it had the longest analysis time - 53 minutes and 31 seconds. The malspec it returned consisted of two graphs.

The first graph contains the following nodes: \code{open}, \code{read}, \code{fstat}, \code{read} and \code{close}, all connected by file descriptor dependencies. The second graph contains a single node, a \code{fork} system call. The child process was not monitored.

\code{Virus.Linux.Osf.8759} showed 

Another interesting malware sample was \code{Virus.Linux.Radix} which inserted itself into the executable file for the \code{ls} command, \code{/bin/ls}, and \code{cp} command, \code{/bin/cp}. It also searched the current directory for executable files and it infected those as well.

Node aggregation reduced the total number of nodes for the dependency graphs, especially in the case of large graphs. In \labelindexref{Figure}{img:node-aggregation-android} we can see the total number of nodes was reduced by a significant factor for \code{Virus.Linux.Osf.8759} and \code{Virus.linux.Snoopy.c}.

\fig[scale=0.6]{src/img/node-aggregation-android.png}{img:node-aggregation-android}{Node aggregation for android.xml}

In \labelindexref{Figure}{img:mal-analysis-time} we present the analysis duration for the malware samples we considered for the android.xml test.

\makeatletter \setlength{\@fptop}{0pt} \makeatother

\fig[scale=0.6]{src/img/mal-analysis-time.png}{img:mal-analysis-time}{Analysis time for android.xml samples}